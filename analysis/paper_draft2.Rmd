---
title: "Bayesian Detection of Bias in Peremptory Challenges Using Historical Strike Data"
date: "`r Sys.Date()`"
blinded: 0
authors:
- name: "[Sachin S. Pandya](https://orcid.org/0000-0001-7387-1307)"
  #thanks: The authors gratefully acknowledge ...
  affiliation: University of Connecticut
  email: sachin.pandya@uconn.edu
- name: "Xiaomeng Li"
  affiliation: University of Connecticut
- name: "[Timothy E. Moore](https://orcid.org/0000-0002-9576-0517)"
  affiliation: University of Connecticut
output: 
  rticles::asa_article:
    citation_package: "default"
    keep_tex: TRUE
    #fig_width: 5
    #fig_height: 5
  #output:
#  pdf_document:
#    latex_engine: xelatex
#    number_sections: true
    #fig_width: 4
    #fig_height: 4
header-includes: 
  - \usepackage{amsmath}
#fontsize: 12pt
bibliography: references.bib
biblio-style: agsm.bst
nocite: |
  @WashR37, @calccp2021
keywords: "Batson challenge, peremptory strikes, power prior, Bayesian"
abstract: |
  US law bars using peremptory strikes during jury selection because of prospective juror race, ethnicity, gender, or membership in certain other cognizable classes. Here, we propose a Bayesian approach for detecting such illegal bias. We show how to incorporate historical data on an attorney's use of peremptory strikes in past cases to estimate how likely that attorney has struck prospective jurors in a current trial because of their cognizable-class membership. In so doing, we use the power prior to adjust the weight of such historical information in the analysis. We show how well our model performs on simulated data. Finally, we extend this approach with a prototype software application to detect bias in peremptory-challenge in real time during jury-selection. We illustrate this application's use with historical strike data from a convenience sample of cases from one court.

---

```{r setup, include=FALSE}

library(ggplot2)
library(dplyr)

knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

```

# Introduction

In the U.S., individuals selected for jury-service appear in court as scheduled and are questioned by the parties' attorneys and the trial judge. During this process, a prospective juror, if not excused by the trial judge for cause, may still be dismissed if a party's attorney uses one of their limited number of peremptory challenges against them. By asserting a peremptory challenge, a party can declare a prospective juror ineligible ("strikes" that juror) for a seat on the jury without the burden of explaining why.

Since _Batson v. Kentucky_ [-@batson1986], a party violates the Equal Protection Clause of the US Constitution by using peremptory challenges if motivated by the prospective jurors' race, ethnicity, gender, or membership in another cognizable class. The party bringing a _Batson_ challenge bears the burden of proving such illegal bias is more likely than not to be true [@LaFave2020, $\S$ 22.3(d)]. For similar challenges under State law, a few States require only that an "objective observer" or an "objectively reasonable person" would find that race, ethnicity or another cognizable-class membership was a "factor" in that party's use of strikes [Wash. General Rule. 37(e); Calif. Code Civil Procedure $\S$ 231.7(d)(1)]. Peremptory-challenge procedure, and thus the task of proving illegal bias, varies not only by State, but also by court, including the number of peremptory challenges assigned to each side and the order in which each party uses those strikes [@nscs-jury2018; @Williams2017].

In any case, evidence of such illegal bias may include data on a party's use of peremptory challenges in past cases [@flowers2019, 2243; Wash. General Rule 37(g)(v); Calif. Code Civil Procedure $\S$ 231.7(d)(3)(G)]. Prior studies have collected historical strike data in past cases and reported the observed difference in strike rates by race or gender. Typically, they test for the probability of observing a non-zero difference in strike rates by the race or gender of the struck prospective jurors, given repeated sampling from a hypothetical population of peremptory strikes with zero such difference [e.g., @Eisenberg2017; @Grosso2012; for discussion, see @Gastwirth2014; @Gastwirth2013]. Prior studies have also modeled how much a prospective juror's race affected the odds of being struck. For different modeling approaches using the same historical strike data from Mississippi, see @Craft2018a; @DeCamp2021; and @Dunn2021.

In this paper, we extend a Bayesian approach to _Batson_ and similar challenges [@Kadane2018a; @Kadane2018b] to incorporate historical strike data. In this approach, we use two steps. In step one, we specify a model of the peremptory-strike process in the court of interest that includes a bias parameter to which we assign an initial prior distribution. We use an attorney's strike data from past trials, as generated by that same peremptory-strike process, to estimate a posterior distribution for that bias parameter. We use the power prior [@Chen2000; @Ibrahim2015] to control how much the strike history from past cases affects the posterior distribution of the bias parameter. In step two, we estimate the posterior distribution of the bias parameter from the current case, using the posterior distribution developed with the historical information and the power prior. 

Here, we demonstrate this approach with simulation studies to test model performance. Then, we present a software prototype that encodes the same approach with actual historical strike data to help attorneys and others detect bias in peremptory-challenge use in real time during jury selection. 

# Methods

## Statistical Procedure

Following @Kadane2018a and @Barrett2007, we model a peremptory-challenge process in which each party strikes prospective jurors in an alternating sequence. Under such a procedure, the trial judge rules on all challenges for cause before the parties exercise any peremptories. Then, of the potential jurors who remain, a subset of them are subject to peremptory strike, usually a number that corresponds to the number seats on the jury (plus alternates, if any). The parties exercise their strikes on anyone among this subset of potential jurors in an alternating sequence. Once all strikes are used or waived, the remaining prospective jurors are each assigned to seats on the jury until those seats are filled.

Accordingly, for any given case $i$ in which jury selection occurs, let $j$ denote a peremptory strike used, and let $\delta_{ij}$ denote whether or not a party used that strike on a person who belongs to a "cognizable class". If "race" is the bias type of interest, the cognizable class is racial minority jurors ($\delta_{ij} =1$, 0 for White jurors).  If "gender" is the bias of interest, the cognizable class is female jurors ($\delta_{ij} = 1$, 0 for male jurors). In turn, let $c_{ij}$ denote the number of cognizable class members subject to strike; and $m_{ij}$ denote the number of cognizable class non-members subject to strike, such that $c_{ij}+m_{ij}$ is the total number of jurors potentially subject to strike. If there is no bias, the probability is $\frac{c_{ij}}{c_{ij}+m_{ij}}$ for striking a cognizable class member, and $1-\frac{c_{ij}}{c_{ij}+m_{ij}}$ for striking someone who does not belong to that class.

By adding one parameter $w$, we can measure _bias_ by different values of $w$ by defining the probability of a cognizable class member being struck to be $\frac{wc_{ij}}{wc_{ij}+m_{ij}}$. To avoid making the weight of the non-cognizable class be the reciprocal of the weight of cognizable class, let $b = log(w)$. 

Accordingly, for any given value of the bias parameter $b$, the probability of strike of a member from either class, or $Pr(\delta_{ij})$, is such that:

\begin{equation}
Pr(\delta_{ij} | b) = 
\begin{cases}
  \frac{(e^b)c_{ij}}{(e^b)c_{ij}+m_{ij}} & \text{for }\delta_{ij}=1\\    
  \frac{m_{ij}}{(e^b)c_{ij}+m_{ij}} & \text{for }\delta_{ij}=0  \label{eq:model1}
\end{cases} 
\end{equation} This Equation \eqref{eq:model1} is equivalent to

\begin{equation}
Pr(\delta_{ij}| b) = (\frac{(e^b)c_{ij}}{(e^b)c_{ij}+m_{ij}})^{\delta_{ij}} (\frac{m_{ij}}{(e^b)c_{ij}+m_{ij}})^{1-\delta_{ij}}
\label{eq:model2}
\end{equation}

Given the strike data we have, i.e., $\delta_{ij}$, $c_{ij}$, and $m_{ij}$, by estimating the value of $b$, we can measure bias when a party is striking potential jurors. If $b = 0$, there is no bias, and the probability of strike is simply a function of the share of cognizable members (non-members) in the pool of prospective jurors that could be struck. If $b>0$, we infer that the the party has bias favoring a strike against a juror falling within the cognizable class (e.g., the juror is a racial minority). Where $b<0$, the party has a preference for a juror within the cognizable class. 

The likelihood function of $b$ is

\begin{equation}  
L(b|\delta) = \prod_{i=1}^{n_i} \prod_{j=1}^{n_j}(\frac{(e^b)c_{ij}}{(e^b)c_{ij}+m_{ij}})^{\delta_{ij}} (\frac{m_{ij}}{(e^b)c_{ij}+m_{ij}})^{1-\delta_{ij}}
\label{eq:model3}
\end{equation} where $n_{i}$ is the total number of jury selections (trials); and $n_j$ is the total number of peremptory strikes. 

## Incorporating historical strike data

We incorporate data on strikes in past cases and allow for adjustment of the weight of that historical strike data on the posterior distribution of the bias parameter. To do this, we introduce the power prior:

\begin{equation}  
\pi(b|D_0,a_0) \propto L(b|D_0)^{a_0}\pi_0(b)
\label{eq:powerprior}
\end{equation} where $0 \le a_0 \le 1$ is the parameter controlling the weight of the historical information; $D_0$ is the observed historical data; $L(b|D_0)$ is the likelihood function of $b$ given the historical data; and $\pi_0(b)$ is the initial prior before the historical data is observed. 

In this paper, we assign a normal prior for $\pi_0(b)$ with mean 0 and standard deviation 2. Unlike @Kadane2018a, who assigned $b$ a prior of $\text{Uniform}(-6,6)$, we assume that the law for _Batson_ and similar challenges entails a weakly-informative prior. For our initial prior of $N(0,2)$, we let $\mu = 0$, because the law assigns the burden of proof in a _Batson_ challenge to the party bringing the challenge. Thus, if the challenging party produces no relevant evidence of illegal bias, the law requires a trial judge to reject the challenge as unproven. This is tantamount to treating zero as the most-likely value of the bias parameter, absent any data. Moreover, we take the law to imply that, absent any data, one must assume that higher degrees of illegal bias are less likely than lower degrees of bias. For this reason, we use a normal (Gaussian) distribution with $\sigma = 2$.

After including the historical information through the power prior, the posterior distribution of $b$ is proportional to the product of likelihood function of $b$ and the power prior of $b$ is 

\begin{equation}
L(b|\delta) \propto L(b|\delta)(L(b|\delta_0))^{a_0}\exp(-\frac{b^2}{8})
\label{eq:model4}
\end{equation} where 

\begin{equation}
L(b|\delta_0) = \prod_{i=1}^{n_{0i}} \prod_{j=1}^{n_{0j}}(\frac{(e^b)c_{0ij}}{(e^b)c_{0ij}+m_{0ij}})^{\delta_{0ij}} (\frac{m_{0ij}}{(e^b)c_{0ij}+m_{0ij}})^{1-\delta_{0ij}}
\label{eq:model5}
\end{equation} is the likelihood function of $b$ given historical data; $n_{0i}$ is the total number of jury selections (trials) in the historical data; $n_{0j}$ is the total number of peremptory strikes in the historical data; and $\delta_{0ij}$ denotes whether or not a party used that strike on a person who belongs to a cognizable class in the historical trials. 

The posterior distribution does not have a closed form.  Accordingly, we used the Metropolis-Hasting algorithm to sample $b$ from the posterior distribution. To measure convergence, we used trace plots, the Gelman-Rubin convergence diagnostic and Geweke’s diagnostics [@Gelman1992;@Gelman1998;@Geweke1992].

## Model Performance on Simulated Data



To evaluate the performance of the proposed method, we conducted a simulation study. The primary aim of these simulations is to examine the effect of the strength of discounting of the historical data by the power prior ($\alpha$), and the size of the historical data set, on our ability to detect bias.

Because we use the power prior, we can control how much we account for the historical strike
data by modifying the discounting parameter $\alpha$. If $\alpha=1$, the historical strike data is equally
weighted with the data on strikes in the current trial. If $\alpha<1$, the historical data are discounted and weighted proportionally less than the current trial data. We assign $\alpha<1$ to evaluate how sensitive the posterior of the bias parameter is to the historical data on strikes. Accordingly, in the simulation study, we evaluated different values of $\alpha$: $\alpha=\{0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1\}$ to show how that parameter affected bias detection .

We generated historical strike data of three sizes (same, double, and triple the size of
current data, i.e., data on one previous trial, two previous trials) using seven different values
of the bias parameter for generating that historical data $b_{hist}=\{-3,-2,-1,0,1,2,3\}$. 

To generate data, we generated strike data for a current trial using seven different values of the bias parameter $b_{curr}=\{0,0.5,1,1.5,2, 2.5,3\}$. These values were selected to evaluate the strength of the power prior as a function of the compatibility between current and historical trial data. As introduced above, $b > 0$ ($b < 0$) represents bias against (for) a prospective juror within (outside) the cognizable class, while $b = 0$ denotes no bias. 

We let $b_{hist}$ differ from $b_{curr}$ (our parameter of interest) to simulate noise associated with
historical strike data that is incomplete not at random, by allowing $b_{hist}$ to have the same selected bias values, i.e., $b_{hist}=\{0,0.5,1,1.5,2, 2.5,3\}$ . Alternatively, this difference simulates a real difference in the bias parameter that depends on a feature of the current trial but
not of all the past trials in the historical data. To illustrate, suppose prosecutor with a bias
value conditional on defendant race: $b > 0$ if the criminal defendant is Black, $b = 0$ if not.
If our historical strike data contains only cases with non-Black defendants, accounting
for that historical data may lead us to underestimate prosecutor’s bias in the current case
$b_{curr}$ with a Black defendant. We note that we assume the defense has no bias.

For our simulation we define bias detection as the proportion of times we identify bias when bias is present in the current trial, i.e., $\b_{curr} > 0$ , based on whether credible intervals of the bias parameter exclude zero. Since we use a weakly-informative prior that pulls the estimate of $b_{curr}$ towards zero, we focus _not_ on how accurately the model can recover the true value of $b_{curr}$ (i.e., a traditional coverage rate), but on how accurately our model can detect that bias. For instance, a 90\% bias detection rate means that in 900 of 1000 model fits, a given credible interval does not contain zero if the $b_{curr}$ is not zero. Put another way, if we set $b_{curr}>0$, we calculate the proportion of the 90\% credible intervals that lie to the right of zero (lower bound is positive) among the 1000 model fits. For each scenario, we generated 1000 data sets and fit the model on those data sets. For each replicate, we generate a MCMC sample of 10000 iterations with a burn-in period of 1000 iterations. For each replicate, we calculate the posterior mean and $80\%$, $90\%$, and $95\%$ highest posterior density (HPD) intervals for $\b_{curr}$. 

Additionally, we present sensitivity analysis for the number of available strikes with 6 strikes, 10 strikes, and 15 strikes. Thus, in total, we considered 4851 different scenarios, i.e. the combination of 7 different bias parameters of current data and of historical data, 3 different amounts of historical data, 11 different values for the power prior weight parameter, and for 3 combinations of the total number of strikes. 

```{r b80, eval = FALSE}

# simulated data via "noseq_simulation.R" script

load_path <- here::here("data-sim","sim_resultc.csv")

sims <- readr::read_csv(load_path)
sims$a.f <- as.factor(sims$a)

sims$sig <- ifelse(sims$L80 <0 & sims$U80 >0 , "ns", 1) 
sims$sig <- ifelse(sims$L80 >0 & sims$U80 >0 , "pos", sims$sig) 
sims$sig <- ifelse(sims$L80 <0 & sims$U80 <0 , "neg", sims$sig) 

sims$sig.n <- 0
sims$sig.n <- ifelse(sims$sig=="pos", 1, sims$sig.n)
sims$sig.n <- ifelse(sims$sig=="neg", 1, sims$sig.n)

```

```{r b90, eval = FALSE}

sims$a.f <- as.factor(sims$a)
sims$sig <- ifelse(sims$L90 <0 & sims$U90 >0 , "ns", 1) 
sims$sig <- ifelse(sims$L90 >0 & sims$U90 >0 , 
                                    "pos", sims$sig) 
sims$sig <- ifelse(sims$L90 <0 & sims$U90 <0 , 
                                    "neg", sims$sig) 
sims$sig.n <- 0
sims$sig.n <- ifelse(sims$sig=="pos", 1, sims$sig.n)
sims$sig.n <- ifelse(sims$sig=="neg", 1, sims$sig.n)

```

```{r b95, eval = FALSE}

sims$a.f <- as.factor(sims$a)
sims$sig <- ifelse(sims$L95 <0 & sims$U95 >0 , "ns", 1) 
sims$sig <- ifelse(sims$L95 >0 & sims$U95 >0 , 
                                    "pos", sims$sig) 
sims$sig <- ifelse(sims$L95 <0 & sims$U95 <0 , 
                                    "neg", sims$sig) 
sims$sig.n <- 0
sims$sig.n <- ifelse(sims$sig=="pos", 1, sims$sig.n)
sims$sig.n <- ifelse(sims$sig=="neg", 1, sims$sig.n)



```

```{r plotsfig1, eval = FALSE}

# simulated data via "noseq_simulation.R" script

load_path <- here::here("data-sim","sim_resultc.csv")

sims <- readr::read_csv(load_path, show_col_types = FALSE)
sims$a.f <- as.factor(sims$a)

library(latex2exp)
xlabel = TeX("$b_{curr}$")
ylabel = TeX("$b_{hist}$")

source(here::here("analysis","R","coverageplot_func.R"))

C80plot <- coverageplot_func(sims, sims$C80, xlabel, ylabel) +
           labs(title = "Coverage Rates - 80% Credible Interval")

C90plot <- coverageplot_func(sims, sims$C90, xlabel, ylabel) +
           labs(title = "Coverage Rates - 90% Credible Interval")

C95plot <- coverageplot_func(sims, sims$C95, xlabel, ylabel) +
           labs(title = "Coverage Rates - 95% Credible Interval")

# output to figures folder

load_path <- here::here("analysis","figures","C80plot.png")
ggsave(load_path, plot = C80plot, height = 4, width = 7)
load_path <- here::here("analysis","figures","C90plot.png")
ggsave(load_path, plot = C90plot, height = 4, width = 7)
load_path <- here::here("analysis","figures","C95plot.png")
ggsave(load_path, plot = C95plot, height = 4, width = 7)

```

```{r fig1, out.width = "95%", fig.cap = "Coverage Rates based on 80 pct credible interval.", fig.align='center'}

load_path <- here::here("analysis","figures","C80plot.png")
knitr::include_graphics(load_path)

```

Figure 1 depicts the bias detection rate with an 95\% credible interval for the n_strikes = 15 scenario. When $b_{curr}$ is high (close to 3) the coverage rate is high, very close to 1. However, when $b_{curr}$ is lower (close to zero), the bias detection rate drops below 0.8. When there is no bias in the current or historical trials ($b_{curr} = b_{hist} = 0$}), our bias detection rate for 95% CI is 0.05 or less. As we place more weight on the historical strike data (as $a$ increases), and the historical strike data is consistent with current information (high compatibility between current and historical trials, the bias detection rate is close to 1, especially when bias is high (upper right-hand corner of plots). Conversely, as alpha decreases, bias detection is only high when there is high bias in the current trial ($b_{curr} >= 1.5). Increasing the number of historical trails leads to an increase in bias detection especially when current and historical trials are compatible.  

```{r fig2, out.width = "95%", fig.cap = "Coverage Rates - 90 pct. Credible Interval", fig.align='center'}

load_path <- here::here("analysis","figures","C90plot.png")
knitr::include_graphics(load_path)

```

Using a wider credible interval lowers this chance of error. For example, with a 90\% credible interval (Figure 2), when $b_{curr} = 2$, the coverage rate is lower than with an 80\% credible interval; when $b_{curr}=0$, the coverage rate is higher. The tradeoff is lower accuracy. With a 90\% credible interval, when the bias parameter is 2, the model is less accurate in detecting bias. When the bias parameter is 3, however, the coverage rate is still high.

```{r fig3, out.width = "95%", fig.cap = "Coverage Rates - 95 pct. Credible Interval", fig.align='center'}

load_path <- here::here("analysis","figures","C95plot.png")
knitr::include_graphics(load_path)

```

Figure 3 depicts coverage rates when using a 95\% credible interval. Here, given $b_{curr} = 0$, the coverage rate is very close to 1. This implies that we are very unlikely to infer bias when there is none. When $b_{curr} = 3$, the coverage rate is still high. This implies that we can still accurately detect the bias when it is strong. However, when the bias is moderate ($b_{curr} = \{2, -2\}$), the coverage rate is only high if we have consistent historical information.

Overall, these simulation results indicate that our model can always accurately detect strong bias. As for moderate bias, detection accuracy increases with more historical strike information. The choice of credible interval ultimately depends on how conservative we want to be when inferring bias.

## Simultaneous Strikes

In some courts, both parties simultaneously exercise their peremptory challenges on the prospective jurors subject to strikes. This simultaneous-strikes process can be modeled as a special case of our model of an alternating-strikes process above (see Equation \eqref{eq:model3}), i.e, as equivalent to one party engaging in an uninterrupted sequence of strikes against a subset of prospective jurors eligible to be struck. The premise: Regardless of the order in which a party announced those strikes, the posterior for the bias parameter would be the same.

```{r simgen, eval = FALSE}

# generate simulated data and output b1.csv, b2.csv, b3.csv

source("R/simultaneous1.R")

```

```{r simltns, eval = FALSE}

# load already-generated data

load_path_b1 <- here::here("data-sim", "b1.csv")
load_path_b2 <- here::here("data-sim", "b2.csv")
load_path_b3 <- here::here("data-sim", "b3.csv")

b1 <- read.csv(load_path_b1)
b2 <- read.csv(load_path_b2)
b3 <- read.csv(load_path_b3)

library(dplyr)

b1.t <- b1 %>% 
  select(-X) %>%
  t() %>% 
  data.frame() %>% 
  dplyr::rename_with(~b1$X) %>%
  mutate(sim = as.character(1:50))
#b1.t$sim <- factor(b1.t$sim, levels = b1.t$sim, ordered = TRUE)

b2.t <- b2 %>% 
  select(-X) %>%
  t() %>% 
  data.frame() %>% 
  dplyr::rename_with(~b2$X) %>%
  mutate(sim =  as.character(1:50))
#b2.t$sim <- factor(b2.t$sim, levels = b2.t$sim, ordered = TRUE)

b3.t <- b3 %>% 
  select(-X) %>%
  t() %>% 
  data.frame() %>% 
  dplyr::rename_with(~b2$X) %>%
  mutate(sim = as.character(1:50))
#b3.t$sim <- factor(b3.t$sim, levels = b3.t$sim, ordered = TRUE)

colnames(b1.t)[1:3] = c('b_s','2.5%','97.5%')
colnames(b2.t)[1:3] = c('b_s','2.5%','97.5%')
colnames(b3.t)[1:3] = c('b_s','2.5%','97.5%')

b1.t$b = "1"
b2.t$b = "2"
b3.t$b = "3"
b.com <- rbind(b1.t, b2.t, b3.t)
b.com$sig <- ifelse(b.com$`2.5%`> 0, "Bias", 
                                  "No Bias")
b.com$b.num <- as.numeric(b.com$b)

b1.mean <-data.frame(b_s = mean(b1.t$b_s), 
                     `2.5%` =  mean(b1.t$`2.5%`),
                     `97.5%` = mean(b1.t$`97.5%`),
                     sim = "mean", 
                     b = "1", 
                     sig = "Bias",
                     b.num = 1)

b2.mean <-data.frame(b_s = mean(b2.t$b_s), 
                     `2.5%` =  mean(b2.t$`2.5%`),
                     `97.5%` = mean(b2.t$`97.5%`),
                     sim = "mean", 
                     b = "2",
                     sig = "Bias",
                     b.num = 2)

b3.mean <-data.frame(b_s = mean(b3.t$b_s), 
                     `2.5%` =  mean(b3.t$`2.5%`),
                     `97.5%` = mean(b3.t$`97.5%`),
                     sim = "mean", 
                     b = "3",
                     sig = "Bias",
                     b.num = 3)

names(b1.mean)<- colnames(b.com)
names(b2.mean)<- colnames(b.com)
names(b3.mean)<- colnames(b.com)
b.com<- rbind(b.com,b1.mean[1,], b2.mean[1,], b3.mean[1,])

b.com$sim.n <- as.numeric(b.com$sim) # produces warning: NAs introduced by coercion
b.com$sim.n[151:153] <- 52.5

library(ggplot2)

cust_labeller_b <- function(x) paste0("b = ", x)

simplot <- ggplot(data = b.com, 
                  aes(x = sim.n, 
                      y = b_s, 
                      color = sig
                      )
                  ) +
  facet_grid(~b, 
             labeller = labeller(b = cust_labeller_b)
             ) +
  geom_point(size = 2)+
  geom_errorbar(aes(x = sim.n, ymin = `2.5%`, 
                    ymax = `97.5%`), width = 0.4)+
  geom_hline(data = b.com, aes(yintercept = b.num), col = "red", lwd = 1.1) +
  geom_hline(yintercept = 0, col = "black", lwd = 1, lty = 1) +
  geom_vline(xintercept = 51.25, col = "black", lwd = .5, lty = 2) +
  xlab("Simulation")+
  scale_color_manual("Bias", values = c("blue", "red"))+
  ylab("Posterior Bias Value")+
  ylim(c(-0.5, 5))+
  scale_x_continuous(breaks = c(1:50, 52.5), labels = c(1:50, "Average"))+
  coord_flip()+
  theme_classic()+
  theme(legend.position = "none",
        #axis.title = element_text(size = 16), 
        axis.text.x = element_text(size = 12), 
        axis.text.y = element_text(size = 9))

load_path <- here::here("analysis","figures","simplot.png")
ggsave(load_path, plot = simplot)

```

To test this premise, we conducted the following simulation study. We first generated a single trial in which one attorney used fifteen strikes in an uninterrupted sequence against 32 prospective jurors, 10 of which were member of a cognizable-class (e.g., Black jurors).  Then, we shuffled the order of those strikes to generate 50 trials with the same proportion of struck cognizable-class members but different orders. We then used the model to fit the 50 trials to see if the estimated bias parameters are close to each other. We conducted the simulation study under three scenarios from moderate bias to strong bias ($b=\{1,2,3\}$). 

```{r fig4, out.width = "75%", fig.cap="Simulation results for simultaneous strikes example. Columns correspond to values of bias used to simulate data. Points and horizontal lines denote estimated posterior mean and 95 pct. credible interval for bias parameter. Vertical lines denote true values of the bias parameters used in the 50 simulations.", fig.align='center'}

load_path <- here::here("analysis","figures","simplot.png")
knitr::include_graphics(load_path)

```

Figure 4 depicts the results. We find the estimated bias parameter of the 50 trials with different strike orders are close to each other for all of the three scenarios. None of their credible intervals include zero. We therefore infer that the order of strikes does not influence the estimate of the bias parameter. This confirms that the simultaneous-strikes process can be modeled as a special case of our model of an alternating-strikes process.

## The Software Prototype

We describe here a prototype software application ("app") that implements the approach described above and that attorneys and others can use in real time to detect bias in the use of peremptory challenges. We built this app with `r R.version$version.string` and the shiny package [@R; @shiny].  

To show how this app might be used by lawyers in real cases, we loaded this app with real strike data from a convenience sample of attorneys who appeared during jury selection in criminal cases in the federal district court for Connecticut during fiscal years 2013 through 2017. To collect this historical strike data, one of us filed a request with the U.S. District Court of Connecticut based on 28 U.S.C. $\S$ 1868.  Thereafter, we received copies of certain jury-selection records associated with twenty-nine criminal cases in that court during this period. These included strike sheets that indicated the identification number of prospective jurors who were struck by peremptory challenge, the order in which they were struck, and which side (prosecutor or defense) struck which juror. Such records also included a tally of answers to juror questionnaires that asked each prospective juror to report their race and gender.

These records, however, often did not indicate the identity of the attorneys exercising the strikes. While the standard forms included a signature line for the attorney, many were left blank or filled with illegible signatures.  Accordingly, we turned to the publicly-available docket sheets for each case for the names of the lawyers who appeared in the case on behalf of the prosecution (the US Attorney's office) or the criminal defendant(s) on the date(s) of jury selection. Where only a single attorney represented a party during jury selection, it was easy to attribute the pattern of strikes to that attorney. Where multiple lawyers appeared for one side, we attributed to each of them that side's pattern of peremptory challenges in that case. In such cases, neither the jury-selection documents nor the docket sheets indicated any hierarchy among multiple lawyers or any other basis to attribute strikes to only one attorney among them. After generating a dataset based on these documents, we kept only strikes where a criminal defendant was represented by an attorney. Finally, to de-identify this dataset, we excluded defendant names and substituted fictitious names for the attorneys using the charlatan package [@charlatan].

With the app, the user uses the pull-down menus to select the cognizable class (top left) and enters by hand the strike information in the case before them in the _strike tally_ table (bottom left). For demonstration purposes, the prototype app comes pre-loaded with a completed strike tally with values that can be changed and rows that can be added or deleted. In the strike tally, `round` denotes the order of strikes, `num_cog` denotes the number of prospective jurors that could be struck that belong to the cognitive class; `total` denotes the total number of prospective jurors that could be struck; `cog` indicates whether the prospective juror actually struck in that round was a member of the cognizable class (1 = yes, 0 = no); and `party` indicates which side used the strike (PP = prosecutor, PD = defense attorney).

For the prototype app, we set two cognizable-class options: race and gender. This was because the standard juror questionnaire did not ask about other possible cognizable classes. The data also did not expressly indicate the race or gender of the criminal defendant(s).

In the default setting, the pull-down menus for prosecutor and defense are set to "None". As a result, the app ignores any historical strike data and estimates the posterior distributions of the bias parameter for prosecutor and defense based only on the strike tally data and the initial prior ($b \sim N(0,2)$). 

```{r inpts}
df <- data.frame(round = c(1:10),
                 num_cog = c(5,5,4,3,2,2,2,2,2,2),
                 total = c(21,20,19,18,17,16,15,14,13,12),
                 cog = c(0,1,1,0,0,1,1,0,0,0),
                 party = rep(c("PP","PD"),5))

knitr::kable(df, caption ="Hypothetical Strike Tally", format = "latex")

```

To illustrate, suppose the strike tally in Table 1 depicts the pattern of strikes in the present case with defense attorney Aaron Waelchi and prosecutor Lawrance Klocko V (both aliases for actual attorneys in the historical strike data). After the user enters this strike tally, the app initially displays two graphs -- one for the prosecution and the defense. Each graph depicts the prior density plot (colored light grey) and posterior density plot (blue and red for defense and prosecution, respectively) for the bias parameter (Figure 5).

```{r figapp1, out.width='75%', fig.cap = "Screenshot of R-Shiny application showing density plots for bias of prosecutor and defense attorney based on data in 'Current strike tally' table. Vertical dotted lines depict 80 pct. credible interval.", fig.align='center'}

load_path <- here::here("analysis","figures","batson_app_screenshots", "batson_app_screenshot1.png")

knitr::include_graphics(load_path)

```

Here, the 80\% credible interval includes zero, indicating no credible to infer bias, given the current strike tally.

To use historical strike data, the user selects a name of the prosecutor or defense attorney from the pull-down menus. If an attorney's name cannot be found, the app has no historical strike data for that attorney. Once selected, the prior and posterior density plots automatically update to account for the pre-loaded historical strike data for that attorney. For the weight to assign that attorney's historical strike data, the default is set to equal weight of historical information and current information ($a = 1$). The user has two other options: half weight ($a = 0.5$) and minimal weight ($a = 0.2$).

In our illustration, we select the names of the prosecutor and defense attorney from their respective pull-down menus; and leave the weight setting to "Equal". The density plots update accordingly (Figure 6).

```{r figapp2, out.width='75%', fig.cap = "Density Plots with Historical Strike Data (Race). Screenshot of R-Shiny application show density plots based on historical and current strike data for prosecutor and defense attorney.", fig.align='center'}

load_path <- here::here("analysis","figures","batson_app_screenshots", "batson_app_screenshot2.png")

knitr::include_graphics(load_path)

```

Now, the credible intervals clearly exclude zero. Thus, we have a credible basis to infer bias against racial-minority prospective jurors in how these attorney use their peremptory challenges in the present case. 

Next, suppose the same scenario, except now the strike tally indicates the pattern of strikes by these attorneys against female prospective jurors. If so, we select "gender" as the cognizable class, and the density plots update accordingly (Figure 7).

```{r figapp3, out.width='75%', fig.cap = "Density Plots with Historical Strike Data (Gender). Screenshot of R-Shiny application show density plots based on historical and current strike data for prosecutor and defense attorney. Equal weight ($a = 1$) applied to historical and current data.", fig.align='center'}

load_path <- here::here("analysis","figures","batson_app_screenshots", "batson_app_screenshot3.png")

knitr::include_graphics(load_path)

```


Here, most of the prosecutor's density curve of both prior and posterior are to the left of zero, indicating the possible bias against male jurors. However, because the 80\% credible interval includes 0, inferring such bias from the strike data alone is unjustified. 

```{r figapp4, out.width='75%', fig.cap = "Density Plots with Historical Strike Data (Gender). Screenshot of R-Shiny application show density plots based on historical and current strike data for prosecutor and defense attorney. Minimal weight ($a = 0.1$) applied to historical data.", fig.align='center'}

load_path <- here::here("analysis","figures","batson_app_screenshots", "batson_app_screenshot4.png")

knitr::include_graphics(load_path)

```

Finally, if we assign minimal weight to the historical strike data ($a = 0.1$), the density plot updates accordingly (Figure 8). Both the prior and posterior density have become flatter and the credible intervals plainly includes zero.

# Discussion

Statistical methods for _Batson_ and similar legal challenges have the purpose of helping to measure how much prospective jurors' race, gender, or other cognizable-class membership affected an attorney's use of peremptory strikes against them. The Bayesian approach here accounts for the extent of the available historical strike data when estimating the posterior for the bias parameter. By incorporating the power prior, one can easily assess how sensitive that posterior estimate is to the available historical strike data. And with a tool like our prototype app, attorneys can use historical strike data to detect bias in real time during jury selection, thus making it easier to raise credible _Batson_ challenges.

At the same time, the Bayesian approach here also requires more from those who would collect the appropriate historical strike data. For example, given the model we used, we required data on the cognitive-class composition of the prospective jurors not just at the time of the first strike, but at each time either party used a strike. Moreover, suppose an attorney of interest exercised strikes in two courts, each with different strike procedures. In some cases, one court's strike procedure can be modeled as a special case of a more general model that applied to another court's procedure (as we showed above). If not, that attorney's historical strike data in one court could not used to estimate the posterior of that attorney's bias parameter, given a current trial in the other court.

Finally, in practice, historical strike data tends to be incomplete at best, because jury-selection records in past cases are hard to get due to court practices and other barriers [@Grosso2017; @Wright2018]. For example, some jurisdictions do not require recording relevant or detailed enough information about prospective jurors who were or could have been struck (e.g., their race or gender). This forces researchers to turn to other data sources, if any, to find that information. And judges and court staff vary in how often they fully complete or maintain the information they are required to record.  This presents an issue for the approach presented here if the missing strike data is missing not at random.

# Acknowledgements

## CRediT Author Statement

Pandya: Conceptualization, Investigation, Software, Writing; 
Li: Conceptualization, Formal Analysis, Software, Writing - original draft; Moore: Conceptualization, Supervision, Visualization. 

# References
