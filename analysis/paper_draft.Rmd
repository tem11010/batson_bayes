---
title: "Detecting Bias in Peremptory Challenges Using Historical Strike Data"
date: "`r Sys.Date()`"
bibliography: references.bib
author:
  - name: "Sachin S. Pandya"
    affiliation: "University of Connecticut"
    orcid_id: 0000-0001-7387-1307
  - name: "Xiaomeng Li"
    affiliation: "University of Connecticut | Ernest & Young"
  - name: "Timothy E. Moore"
    affiliation: "University of Connecticut"
    orcid_id: 0000-0002-9576-0517
output: distill::distill_article
---

# Introduction

This paper presents a way to use historical data on an attorney's use of peremptory strikes in past trials to estimate, in a current trial, how likely an attorney has used peremptory challenges because of prospective juror race or gender in violation of _Batson v. Kentucky_ (1986), and its progeny.

In the US, individuals selected for jury-service appear in court as scheduled and are questioned by the parties' attorneys and the trial judge.  During this process, a prospective juror, if not excused by the trial judge for cause, may still be dismissed (declared ineligible for a seat on the jury) if a party's attorney uses a peremptory challenge against them. 

# Background and Related Literature

With a peremptory challenge, a party declares a prospective juror ineligible ("strikes" that juror) for a seat on the jury without the burden of explaining why. While some jurisdictions have abolished peremptory strikes (Criminal Justice Act 1988, s 118(1) (UK); S.C. 2019, c. 25, s 269 (Canada)), federal and State law in the United States (except in Arizona^[Arizona Rule of Criminal Procedure XX]) authorize their use during jury selection in criminal and civil cases. In these cases, peremptory-challenge procedure can vary not only by State, but also by court and judge, including the number of peremptory challenges assigned to each side, the order of strikes, and the number of peremptory strikes each party may exercise at a time [@nscs-jury2018; @Williams2017].

Under the "struck jury" method of peremptory challenges, the trial judge decides whether to accept or reject all challenges for cause - for which a reason must be given -- before the parties exercise any peremptories. Thereafter, the number of potential jurors who remain is typically the sum of number of seats on the jury (plus alternates, if any) and the number of peremptory challenges allotted to both sides. 

Then, the parties exercise their strikes on those potential jurors. In one procedure, the parties submit their strikes simultaneously. In another variant, the parties strike in an alternating sequence, with the prosecution striking first. Where the number of strikes are not the same for the parties, an alternating sequence may result in one party exercising multiple strikes consecutively. Once the parties have used (or waive) their strikes, the jurors are seated based on the order in which they were selected or at random.

Under a "strike-and-replace" or "jury box" method, enough potential jurors are seated to fill the jury box. Some of them are excused for cause, and the parties decide whether or not to strike any of the remaining jurors with their peremptory challenges.  Once that is completed, new potential jurors take the seats of the excused or stricken jurors, and the process repeats until all the jury seats are filled.  At any point, strikes can be used on anyone in the jury box.

<!--

Note: Constitutionality of Canada's abolition of strikes upheld in https://decisions.scc-csc.ca/scc-csc/scc-csc/en/item/18932/index.do

Courts also vary as to the number of peremptory strikes a party exercises at a time [@Williams2017, p. 297-298]. This particularly matters where each side does not have the same number of strikes.  For example, if the prosecution has six strikes and the defendant has ten, the custom may be to allow one prosecutor strike, then _two_ defense strikes, then the second prosecutor strike, then two more defense strikes, and so on, until all the strikes are exercised.

-->

This paper focuses on _Batson_ challenges to a party's use of peremptory challenges. Under the US Supreme Court's decision in _Batson v. Kentucky_ (1986), a party's exercise of a peremptory challenge against one or more prospective jurors violates the Equal Protection Clause of the US Constitution if motivated by such jurors' race, ethnicity, gender, or certain other protected characteristics. 

For a _Batson_ challenge, the challenging party must typically establish a "prima facie case", that is, enough evidence to infer that a party struck a juror because of such juror's race, gender, or other protected status. If so, the burden shifts to the challenged party to produce one or more nondiscriminatory reasons for that strike. Thereafter, the challenger must persuade the trial judge that prospective jurors' race or gender, not the proffered nondiscriminatory reason(s), was more likely than not the real motivation for the challenged strike(s) [@LaFave2020, sec. 22.3]. For similar challenges under State law, some States have reduced or eliminated the challenger's burden to establish a prima facie case [e.g., State v. Holloway, 209 Conn. 636, 646 & n.4 (1989); State v. Chapman, 317 S.C. 302, 305-06 (1995)], while other States have shifted the inquiry away from the striking party's motives to whether a hypothetical "objective observer" would find that race or ethnicity was a "factor" in that party's use of strikes [e.g., Wash. R. 37(e)].

Despite _Batson_ and its progeny, "prosecutors in criminal cases, and defense attorneys in civil case are more likely to use their challenges to dismiss African American jurors, whereas criminal defense attorneys and civil plaintiff's attorneys are more likely to exercise their strikes on white prospective jurors." [@Diamond2018]. Possible explanations include attorney fear that even raising a _Batson_ challenge raises with it the embarrassment and discomfort associated with accusing another attorney of being racist [@OBrien2019, 29; @Offit2021]. Similarly, a trial judge deciding a _Batson_ challenge may similarly be reluctant to find against opposing counsel, particularly if that prosecutor repeatedly appears before that judge.

By law, evidence supporting a _Batson_ challenge may include not only the circumstances of the jury selection itself, but also data on peremptory challenges in past cases. For example, in a _Batson_ challenge against a prosecutor in a criminal case, such historical data would be relevant to whether (1) to conclude that the defendant has a prima facie case; (2) to believe a prosecutor from that office who has offered a race-neutral explanation for striking, say, an African-American juror in that case; and (3) to ultimately accept or reject a Batson challenge in that case [e.g., Miller-El v. Dretke, 545 U.S. 231, 253 (2005); Riley v. Taylor, 277 F.3d 261, 280-81, 283 (3d Cir. 2001); Cochran v. Herring, 43 F.3d 1404, 1412 (11th Cir. 1995)]. The US Supreme Court recently identified evidence for a _Batson_ challenge as including the "relevant history of the State's peremptory strikes in past cases" [Flowers v. Mississippi, 139 S. Ct. 2228, 2243 (2019)].

Prior work on statistical methods for _Batson_ challenges, however, has largely focused on strike data from a single case [e.g. @Barrett2007; @Gastwirth2016; @Kadane2018; @Kadane2018a], perhaps because strike data from past cases is hard to collect. Jury-selection records are often not readily available, because they are kept, if at all, by court staff somewhere other than the case file.  Such records are also largely on paper, not electronic or machine-readable formats [@Grosso2017; @Wright2018], and otherwise requires painstaking effort to collect [e.g., @Craft2018]. 

Moreover, strike data on past trials may be missing information not at random [e.g., @Baldus2001, 132-134]. Possible reasons include that some jurisdictions do not require recording relevant or detailed enough information about jurors who were or could have been struck (e.g., their race or gender), thus forcing lawyers and researchers to turn to other data sources (e.g., voter registration rolls), if any, to find that information. Finally, judges and court staff vary in how often they fully complete or maintain the information they are required to record.

When collecting strike data in multiple trials, prior studies have aggregated strikes across those trials, reported the observed difference in strike rates by race or gender, and tested for the probability of observing a non-zero difference in strike rates by race or gender, given repeated sampling from a hypothetical population of peremptory strikes with zero such difference. For example, Eisenberg [-@Eisenberg2017, 334-339] used a 2-tail Fisher's exact test on the observed difference in peremptory strikes by race and gender in a non-random sample of thirty-five trials from 1997-2012 that resulted in death sentences (out of 63 such trials). @Gastwirth2013 has criticized the use of a paired t-test to compare the differences in strike rates of Black and non-Black venire members in the aggregate. Rather, both they and @Gastwirth2014 argued for applying the Cochran–Mantel–Haenszel test by taking the difference of the sum of the observed numbers of Black venire members challenged in each trial and the corresponding sum of the expected numbers of Blacks challenged, and then comparing it to the standard deviation of the difference.

Prior studies have also modeled how much a prospective juror's race affected the odds of being struck [e.g., @Baldus2001]. For exmpale, using jury selection data for 1992-2017 for Mississippi's Fifth Circuit Court District, Craft [-@Craft2018a, 9] applied a logistic regression model to analyze how much a prospective juror's race affected the odds of being struck by the state. For studies applying other modeling techniques to this Mississippi data, see @DeCamp2020 (propensity score matching) and @Dunn2021 (optimal feature selection, optimal classification trees).

# Discussion

Here, we use a Bayesian approach for detecting illegal bias for _Batson_ challenges based solely on an attorney's pattern of peremptory challenges in both a current trial and that attorney's strikes in past cases. First, we specify a model of the peremptory-strike process in the court of interest. Second, we assign an initial prior distribution for a bias parameter $b$. Third, we use an attorney's strike data from past trials, as  generated by the same peremptory-strike process, to estimate a posterior distribution for $b$.  Finally, we use that posterior distribution as the prior for $b$ in the present case and update the posterior based on data on the target attorney's strikes in that present case. 

In so doing, we make two main contributions. First, we use the power prior to control how much the strike history from past cases affects the posterior distribution of the bias parameter $b$. The power prior is a way to create informative prior distributions based on historical data so as to control how much historical data affects the posterior distribution of some parameter of interest. The key insight is to raise the likelihood function based on the historical data to a power parameter [@Ibrahim2000; @Ibrahim2015].

Second, we implement the analysis as prototype software that an attorney could use in real time during jury selection to assess how likely an attorney striking prospective jurors in violation of _Batson_.

# Model 1: Alternating Strikes

Following @Kadane2018 and @Barrett2007, we model a struck-jury peremptory-challenge process in which each party strikes prospective jurors in an alternating sequence.

For any given case $i$ in which jury selection occurs, let $j$ denote a peremptory strike used, and let $\delta_{ij}$ denote whether or not a party used that strike on a person who belongs to a "cognizable class". If "race" is the bias type of interest, the cognizable class is racial minority jurors ($\delta_{ij} =1$, 0 for White jurors).  If "gender" is the bias of interest, the cognizable class is female jurors ($\delta_{ij} = 1$, 0 for male jurors). 

In turn, let $c_{ij}$ denote the number of cognizable class members subject to strike; and $m_{ij}$ denote the number of cognizable class non-members subject to strike, such that $c_{ij}+m_{ij}$ is the total number of jurors potentially subject to strike. If there is no bias, the probability is $\frac{c_{ij}}{c_{ij}+m_{ij}}$ for striking a cognizable class member, and $1-\frac{c_{ij}}{c_{ij}+m_{ij}}$ for striking someone who does not belong to that class.

By adding one parameter $w$, we can measure the bias by different values of $w$ by defining the probability of a cognizable class member being struck to be $\frac{wc_{ij}}{wc_{ij}+m_{ij}}$. To avoid making the weight of the non-cognizable class be the reciprocal of the weight of cognizable class, let $b = log(w)$. Accordingly, for any given value of the bias parameter $b$, the probability of strike of a member from either class, or $Pr(\delta_{ij})$, is shown in equation \@ref(eq:model1)

\begin{equation}
Pr(\delta_{ij} | b) = 
\begin{cases}
  \frac{(e^b)c_{ij}}{(e^b)c_{ij}+m_{ij}} & \text{for }\delta_{ij}=1\\    
  \frac{m_{ij}}{(e^b)c_{ij}+m_{ij}} & \text{for }\delta_{ij}=0  
\end{cases} (\#eq:model1)
\end{equation}

This is equivalent to

$$Pr(\delta_{ij}| b) = (\frac{(e^b)c_{ij}}{(e^b)c_{ij}+m_{ij}})^{\delta_{ij}} (\frac{m_{ij}}{(e^b)c_{ij}+m_{ij}})^{1-\delta_{ij}}$$

Given the strike data we have, i.e., $\delta_{ij}$, $c_{ij}$, and $m_{ij}$, by estimating the value of $b$, we can measure bias when a party is striking potential jurors. If $b = 0$, there is no bias, and the probability of strike is simply a function of the share of cognizable members (non-members) in the pool of prospective jurors that could be struck. If $b>0$, we infer that the the party has bias favoring a strike against a juror falling within the cognizable class (e.g., the juror is a racial minority). Where $b<0$, the party has a preference for a juror within the cognizable class. 

The likelihood function of $b$ is shown in equation \@ref(eq:model2)

\begin{equation}  
L(b|\delta) = \prod_{i=1}^{n_i} \prod_{j=1}^{n_j}(\frac{(e^b)c_{ij}}{(e^b)c_{ij}+m_{ij}})^{\delta_{ij}} (\frac{m_{ij}}{(e^b)c_{ij}+m_{ij}})^{1-\delta_{ij}} (\#eq:model2)
\end{equation}

where $n_{i}$ is the total number of jury selections (trials); and $n_j$ is the total number of peremptory strikes. 

Next, we assign an initial prior:

\[b \sim \text{Normal}(0,2)\]

Unlike @Kadane2018, who assigned $b$ a prior of $Uniform (-6,6)$, because the law assigning the burden of proof for _Batson_ challenges entails a weakly-informative prior. 

First, for our initial prior of $N(0,2)$, we let $\mu = 0$, because the law assigns the burden of proof in a _Batson_ challenge to the party bringing the challenge as well as the initial burden of producing some relevant evidence of illegal bias (the _Batson_ prima facie case). Thus, if that challenging party in fact produces no relevant evidence of illegal bias, the law requires a trial judge to reject the challenge as unproven. This is tantamount to treating zero as the most-likely value of the bias parameter, absent any data.

Second, we take that law as requiring, absent any data, the assumption that higher degrees of illegal bias (preference) are less likely than lower degrees of bias (preference). By using a normal (Gausian) distribution with $\sigma = 2$, we encode this assumption by making values of the bias parameter less likely as they move further from zero and by making very unlikely values any value of $b$ greater than two standard deviations from the mean.

Finally, we want to incorporate historical data on strikes in past cases and adjust the weight of that historical information on the posterior distribution of the bias parameter.  Accordingly, we introduce the power prior \@ref(eq:model3)

\begin{equation}
\pi(b|D_0,a_0) \propto L(b|D_0)^{a_0}\pi_0(b) (\#eq:model3)
\end{equation}

where $0 \le a_0 \le 1$ is the parameter controlling the weight of the historical information; $D_0$ is the observed historical data; $L(b|D_0)$ is the likelihood function of $b$ given the historical data; and $\pi_0(b)$ is the initial prior before the historical data is observed. In this paper, we assume a normal prior for $\pi_0(b)$ with mean 0 and standard deviation 2. 

After including the historical information through the power prior, the posterior distribution of $b$  is proportional to the product of likelihood function of $b$ and the power prior of $b$ as shown in \@ref(eq:model4) 

\begin{equation}
L(b|\delta) = L(b|\delta)(L(b|\delta_0))^{a_0}\exp(-\frac{b^2}{8}) (\#eq:model4)
\end{equation}

where $L(b|\delta_0) = \prod_{i=1}^{n_{0i}} \prod_{j=1}^{n_{0j}}(\frac{(e^b)c_{0ij}}{(e^b)c_{0ij}+m_{0ij}})^{\delta_{0ij}} (\frac{m_{0ij}}{(e^b)c_{0ij}+m_{0ij}})^{1-\delta_{0ij}}$ is the likelihood function of $b$ given historical data. $n_{0i}$ is the total number of jury selections in the historical data, and $n_{0j}$ is the total number of peremptory strikes in the historical data. $\delta_{0ij}$ denote whether or not a party used that strike on a person who belongs to a "cognizable class" in the historical trials.   

The posterior distribution does not have a closed form.  Accordingly, we used the Metropolis-Hasting algorithm to sample $b$ from the posterior distribution. To measure convergence, we used traceplots, the Gelman-Rubin convergence diagnostic [@Gelman1992; @Gelman1998] and Geweke’s diagnostics [@Gewe1992]. 

# Simulation 

We conducted a simulation study to measure model performance under different values of the bias parameter $b$ and different amounts and kinds of historical information. 

To do this, we generated strike data for a current trial using seven different values of the bias parameter ("current" $b = {-3,-2,-1,0,1,2,3}$. As introduced above, $b>0$ ($b<0$) represents a bias against (preference) for a prospective juror within (outside) the cognizable class, while $b=0$ denotes neither bias or preference. A greater absolute value of $b$ represents greater bias against or preference for the cognizable class.

We also generated historical strike data of three sizes (same, double, and triple the size of current data, i.e., data on one previous trial, two previous trials) using seven different values of the bias parameter for generating that historical data ( _historical_ $b = {-3,-2,-1,0,1,2,3}$).

We let historical $b$ differ from current $b$ (our parameter of interest) to simulate noise associated with historical strike data that is incomplete not at random. Alternatively, this difference simulates a real difference in the bias parameter that depends on a feature that the current trial has but that all the past trials in the historical data do not. To illustrate, assume a prosecutor with two true bias values: $b > 0$ if the criminal defendant is Black, $b = 0$ if not. If our historical strike data contains only in cases with non-Black defendants, accounting for that historical data may lead us to underestimate prosecutor's bias $b$ in the current case with a Black defendant.

By using the power prior, we can control the weight that we put on historical data by modifying the weight parameter $a$. If $a = 1$, the historical strike data is equally weighted with the present data on strikes. If $a < 1$, the historical data matters proportionally less. We can assign $a < 1$ to evaluate how sensitive the posterior of the bias parameter is to the historical data on strikes. Accordingly, in the simulation study, we tried different values of the weight parameter $a = (0.1,0.3,0.5,0.7,1)$ to show how that parameter affected modeling accuracy. 

We considered 735 scenarios in total, i.e., the combination of 7 different bias parameters of current data and of historical data, 3 different amounts of historical data and 5 different values of the power prior weight parameter $a$. For each scenario, we generated 1000 datasets and fit the model on those datasets. We recorded the mean value of the posterior mean and credible intervals of one thousand model fits for each scenario.

In turn, for three credible interval levels (80\%, 90\% and 95\%), we recorded the coverage rates, i.e., the proportion of times those intervals actually contained the true value of the (current) bias parameter $b$. For instance, a 90\% coverage rate means that in 900 of 1000 model fits, a given credible interval contained what we fixed as the value of current $b$. Put another way, if we set $b>0$, we calculate the proportion of the 90\% credible intervals that lie to the right of zero among the 1000 model fits. 

The following figures depict the coverage rates of $b$ under the 80\% credible interval (Figure \@ref(fig:b80)), under the 90\% credible interval (Figure \@ref(fig:b90)), and under the 95\% credible interval (Figure \@ref(fig:b95)).

```{r b80, echo=FALSE, fig.cap="80% credible interval"}

library(ggplot2)

# INSERT simulation and plot code

load_path <- here::here("sim_resultc.csv")

sims <- readr::read_csv(load_path)
sims$a.f <- as.factor(sims$a)

sims$sig <- ifelse(sims$L80 <0 & sims$U80 >0 , "ns", 1) 
sims$sig <- ifelse(sims$L80 >0 & sims$U80 >0 , 
                                    "pos", sims$sig) 
sims$sig <- ifelse(sims$L80 <0 & sims$U80 <0 , 
                                    "neg", sims$sig) 
sims$sig.n <- 0
sims$sig.n <- ifelse(sims$sig=="pos", 1, sims$sig.n)
sims$sig.n <- ifelse(sims$sig=="neg", 1, sims$sig.n)

p = ggplot()+
  geom_tile(data = sims, aes(x = d, y = d_h,
                        fill = as.factor(sig.n)),
            color="black")+
  facet_grid(h~a, labeller = label_both)+
  # scale_fill_gradient2(expression(hat(d)), 
  #                      low = "darkred", mid = "white", 
  #                      high = "blue", 
  #                      breaks = c(-3, -2, -1, 0, 1, 2, 3), 
  #                      limits = c(-3.2, 3.2),
  #         labels = c("Neg bias", "", "", "NS","", "", "Bias"))+
  scale_x_continuous(breaks = c(-3:3), expand = c(0,0))+
  scale_y_continuous(breaks = c(-3:3), expand = c(0,0))+
  xlab("Current b")+
  ylab("Historical b")+
  scale_fill_manual(values = c("white", "blue"))+
  coord_equal()+
  theme_minimal()+
  labs(fill = "coverage") +
  theme(axis.text = element_text(size =10), 
        #axis.title = element_text(size = 16), 
        #legend.title.align = 0.05, 
        #legend.title = element_text(size = 16), 
        legend.text = element_text(size = 14))
p

```


```{r b90, echo=FALSE, fig.cap="90% credible interval"}

# INSERT simulation and plot code
sims$a.f <- as.factor(sims$a)
sims$sig <- ifelse(sims$L90 <0 & sims$U90 >0 , "ns", 1) 
sims$sig <- ifelse(sims$L90 >0 & sims$U90 >0 , 
                                    "pos", sims$sig) 
sims$sig <- ifelse(sims$L90 <0 & sims$U90 <0 , 
                                    "neg", sims$sig) 
sims$sig.n <- 0
sims$sig.n <- ifelse(sims$sig=="pos", 1, sims$sig.n)
sims$sig.n <- ifelse(sims$sig=="neg", 1, sims$sig.n)

p = ggplot()+
  geom_tile(data = sims, aes(x = d, y = d_h,
                        fill = as.factor(sig.n)),
            color="black")+
  facet_grid(h~a, labeller = label_both)+
  # scale_fill_gradient2(expression(hat(d)), 
  #                      low = "darkred", mid = "white", 
  #                      high = "blue", 
  #                      breaks = c(-3, -2, -1, 0, 1, 2, 3), 
  #                      limits = c(-3.2, 3.2),
  #         labels = c("Neg bias", "", "", "NS","", "", "Bias"))+
  scale_x_continuous(breaks = c(-3:3), expand = c(0,0))+
  scale_y_continuous(breaks = c(-3:3), expand = c(0,0))+
  xlab("Current b")+
  ylab("Historical b")+
  scale_fill_manual(values = c("white", "blue"))+
  coord_equal()+
  theme_minimal()+
  labs(fill = "coverage") +
  theme(axis.text = element_text(size =10), 
        axis.title = element_text(size = 16),
        legend.title.align = 0.05, 
        legend.title = element_text(size = 16), 
        legend.text = element_text(size = 14))
p
```

```{r b95,  echo=FALSE,fig.cap="95% credible interval"}

# INSERT simulation and plot code
sims$a.f <- as.factor(sims$a)
sims$sig <- ifelse(sims$L95 <0 & sims$U95 >0 , "ns", 1) 
sims$sig <- ifelse(sims$L95 >0 & sims$U95 >0 , 
                                    "pos", sims$sig) 
sims$sig <- ifelse(sims$L95 <0 & sims$U95 <0 , 
                                    "neg", sims$sig) 
sims$sig.n <- 0
sims$sig.n <- ifelse(sims$sig=="pos", 1, sims$sig.n)
sims$sig.n <- ifelse(sims$sig=="neg", 1, sims$sig.n)

p = ggplot()+
  geom_tile(data = sims, aes(x = d, y = d_h,
                        fill = as.factor(sig.n)),
            color="black")+
  facet_grid(h~a, labeller = label_both)+
  # scale_fill_gradient2(expression(hat(d)), 
  #                      low = "darkred", mid = "white", 
  #                      high = "blue", 
  #                      breaks = c(-3, -2, -1, 0, 1, 2, 3), 
  #                      limits = c(-3.2, 3.2),
  #         labels = c("Neg bias", "", "", "NS","", "", "Bias"))+
  scale_x_continuous(breaks = c(-3:3), expand = c(0,0))+
  scale_y_continuous(breaks = c(-3:3), expand = c(0,0))+
  xlab("Current b")+
  ylab("Historical b")+
  scale_fill_manual(values = c("white", "blue"))+
  coord_equal()+
  theme_classic()+  
  labs(fill = "coverage") +
  theme(axis.text = element_text(size =10), 
        axis.title = element_text(size = 16), 
        legend.title.align = 0.05, 
        legend.title = element_text(size = 16), 
        legend.text = element_text(size = 14))
p
```

In these figures, _historical b_ denotes the bias parameter for the generated historical data, and current $b$ means the bias parameter for the current data. The values on the right side represent the size of the historical data. The values on the top of the plots represent the power prior weight parameter $a$. Blue means the credible interval for $b$ excludes zero. 

These plots indicate that our model can detect strong bias and bias ($b = \{-3, -2, 2,3\}$). When bias is moderate ($b = \{1, -1\}$), the model can detect it if the historical data has a bias parameter in the same direction. If the bias parameter of historical data is in an opposite direction, the model may provide a wrong estimate of current bias parameter. 

# Model 2: Simultaneous Strikes

In some courts, both parties simultaneously exercise their peremptory challenges on the prospective jurors in a venire.  This may result in both sides using a strike each on the same potential juror. 

For any given case $i$ in which jury selection occurs and a party uses $s$ number of strikes under this process, @Barrett2007 models the probability of a party striking at least $x$ cognizable-class members at random as following a hypergeometric distribution:

$$
Pr(X \geq x) = \sum_{x}^{s} \frac{{c_{i} \choose x} {m_{i} \choose s - x}}{{c_{i} + m_{i} \choose s}}.
$$
where $x = 0, 1, 2, 3, . . . s$; $c_{i}$ denotes the number of cognizable class members in the venire subject to strike; and $m_{i}$ denotes the number of cognizable class non-members in the venire subject to strike.

Here, we argue that a simultaneous-strikes process can be modeled as a special case of our model of an alternating-strikes process above, i.e, one party engages in an uninterrupted sequence of strikes against members of the venire. The premise: Regardless of the order in which a party announced those strikes, the posterior for the bias parameter would be the same.

To show this, we conducted the following simulation study. We first generate a trial and then shuffle the order of the strikes to generate 50 trials with the same proportion of struck cognizable class members but different orders. We then use the model to fit the 50 trials to see if the estimated bias parameter are close to each other. We conduct the simulation study under three scenarios from moderate bias to strong bias, that is $b=1,2,3$. The results are shown in figure \@ref(fig:simltns).

```{r simltns, echo=FALSE,fig.cap="simultaneous case"}

library(dplyr)
library(ggplot2)
#library(conflicted)
#conflict_prefer("select", "dplyr")
#conflict_prefer("filter", "dplyr")

# ADD SCRIPT FOR GENERATING b1.csv, b2.csv, b3.csv

load_path_b1 <- here::here("b1.csv")
load_path_b2 <- here::here("b2.csv")
load_path_b3 <- here::here("b3.csv")

b1 <- read.csv(load_path_b1)
b2 <- read.csv(load_path_b2)
b3 <- read.csv(load_path_b3)

b1.t <- b1 %>% select(-X) %>%
  t() %>% data.frame() %>% 
  dplyr::rename_with(~b1$X) %>%
      mutate(sim = as.character(1:50))
#b1.t$sim <- factor(b1.t$sim, levels = b1.t$sim, ordered = TRUE)

b2.t <- b2 %>% select(-X) %>%
  t() %>% data.frame() %>% 
  dplyr::rename_with(~b2$X) %>%
  mutate(sim =  as.character(1:50))
#b2.t$sim <- factor(b2.t$sim, levels = b2.t$sim, ordered = TRUE)

b3.t <- b3 %>% select(-X) %>%
  t() %>% data.frame() %>% 
  dplyr::rename_with(~b2$X) %>%
  mutate(sim = as.character(1:50))
#b3.t$sim <- factor(b3.t$sim, levels = b3.t$sim, ordered = TRUE)

colnames(b1.t)[1:3] = c('b_s','2.5%','97.5%')
colnames(b2.t)[1:3] = c('b_s','2.5%','97.5%')
colnames(b3.t)[1:3] = c('b_s','2.5%','97.5%')

b1.t$b = "1"
b2.t$b = "2"
b3.t$b = "3"
b.com <- rbind(b1.t, b2.t, b3.t)
b.com$sig <- ifelse(b.com$`2.5%`>0, "Bias", 
                                  "No Bias")
b.com$b.num <- as.numeric(b.com$b)

b1.mean <-data.frame(b_s = mean(b1.t$b_s), 
                     `2.5%` =  mean(b1.t$`2.5%`),
                     `97.5%` = mean(b1.t$`97.5%`),
                     sim = "mean", 
                     b = "1", 
                     sig = "No Bias", 
                     b.num = 1)
b2.mean <-data.frame(b_s = mean(b2.t$b_s), 
                     `2.5%` =  mean(b2.t$`2.5%`),
                     `97.5%` = mean(b2.t$`97.5%`),
                     sim = "mean", 
                     b = "2", 
                     sig = "Bias", 
                     b.num = 2)
b3.mean <-data.frame(b_s = mean(b3.t$b_s), 
                     `2.5%` =  mean(b3.t$`2.5%`),
                     `97.5%` = mean(b3.t$`97.5%`),
                     sim = "mean", 
                     b = "3", 
                     sig = "Bias", 
                     b.num = 3)


names(b1.mean)<- colnames(b.com)
names(b2.mean)<- colnames(b.com)
names(b3.mean)<- colnames(b.com)
b.com<- rbind(b.com,b1.mean[1,], b2.mean[1,], b3.mean[1,])
b.com$sim.n <- as.numeric(b.com$sim)
b.com$sim.n[151:153] <- 52.5

ggplot(data = b.com, aes(x = sim.n, y = b_s, color = sig))+
  facet_grid(~b)+
  geom_point(size = 3)+
  geom_errorbar(aes(x = sim.n, ymin = `2.5%`, 
                    ymax = `97.5%`), width = 0.4)+
  geom_hline(data = b.com, aes(yintercept = b.num), col = "red", lwd = 1.1) +
  geom_hline(yintercept = 0, col = "black", lwd = 1, lty = 1) +
  geom_vline(xintercept = 51.25, col = "black", lwd = 1, lty = 2) +
  xlab("Simulation")+
  scale_color_manual("Bias", values = c("blue", "grey"))+
  ylab("Posterior Bias Value")+
  ylim(c(-0.5, 5))+
  scale_x_continuous(breaks = c(1:50, 52.5), labels = c(1:50, "Average"))+
  coord_flip()+
  theme_classic()+
  theme(axis.title = element_text(size = 16), 
        axis.text.x = element_text(size = 12), 
        axis.text.y = element_text(size = 9))
```
The points represent the estimated posterior mean and the lines represent the 95\% credible interval. The blue line means the credible interval does not include zero, thus indicating a bias, while the grey line means the credible interval includes zero and indicating no bias. We can find the estimated bias parameter of the 50 trials with different orders are close to each other for all of the three scenarios, indicating the order does not influence the estimate of the bias parameter. This is consistent with our previous premise and confirms that the simultaneous-strikes process can be modeled as a special case of our model of an alternating-strikes process.  


# The App Prototype

Even with agreement on the appropriate statistical analysis, it is often hard to complete the analysis in real time _during_ jury selection, unless "statisticians accompany attorneys in the jury selection process or a convenient programme or app is developed." [@Kadane2018, 12]

Following this suggestion, we describe here a prototype software application ("app") that implements the approach described above using `r R.version$version.string`[@R] and shiny [@shiny].

There is currently historical information of some prosecutors and defendants. More historical information would be updated when available. Users can input the current trial information as shown in table \@ref(tab:inpts), and then select the name of the prosecutor and the defendant from the pull-down window if applicable. If the name of the prosecutor or the defense attorney cannot be found, it means the historical information is not available.

The main screen displays two graphs -- one for the prosecution and the defense - that displays the prior density plot and the posterior density plot for the bias parameter.

```{r inpts, echo=FALSE}
df <- data.frame(round = c(1:10),
                 num_cog = c(4,4,4,3,2,2,2,2,2,2),
                 total = c(15,14,13,12,11,10,9,8,7,6),
                 cog = c(0,1,1,0,0,1,1,0,0,0),
                 party = rep(c("PP","PD"),5))
knitr::kable(df)
```

For instance, if we collect the data of a new trial with prosecutor being "Brian P. Leaming" and defendant being "Frank J. Riccio II", and we would like to see if they are biased or not. We can select the name from the pull-down window of prosecutor and defendant to extract the historical information. Then we can input the current trial information, and select the weight that we would like to put on the historical information. Currently we provide three options for the weight, equal weight of historical information and current information, half weight of historical information and low weight of historical information. We can also select the cognizable class that we are interested in. There are currently two options of cognizable class, race and gender. Suppose the current trial information is as we show in table \@ref(tab:inpts), we put equal weight on historical information and we select cognizable class as race, then the posterior density as shown in figure \@ref(fig:brian) will be displayed. 

```{r brian, echo=FALSE,fig.cap="Posterior Density Plot"}
library(dplyr)
library(Rcpp)
load_path2 <- here::here("app/mh_sampler_pp.cpp")
load_path3 <- here::here("app/jury_data_cleaned_new.rds")
sourceCpp(load_path2)
sourceCpp(load_path2)
dat0 <- readRDS(load_path3)
df <- data.frame(round = c(1:10),
                 num_cog = c(4,4,4,3,2,2,2,2,2,2),
                 total = c(15,14,13,12,11,10,9,8,7,6),
                 cog = c(0,1,1,0,0,1,1,0,0,0),
                 party = rep(c("PP","PD"),5))
extract_atny <- function(atny_name,pp,dat){
  if(pp){
    idx = sapply(1:nrow(dat),function(x) grepl(atny_name, dat$P_atty_l[x], fixed=TRUE))
    return(dat[which(idx),])
  }
  else{
    idx = sapply(1:nrow(dat),function(x) grepl(atny_name, dat$D_atty_l[x], fixed=TRUE))
    return(dat[which(idx),])
  }
} 
organize_input <- function(dat,pp,cog){
  dat_strikes <- dat %>% filter(!is.na(strike_seq)) 
  if(cog=='gender'){
    dat_strikes <- dat_strikes %>% filter(!is.na(sex))
  }else{
    dat_strikes <- dat_strikes %>% filter(!is.na(race))
  }
  
  dat_strikes <- dat_strikes[order(dat_strikes$strike_seq),]
  if(cog=='gender'){
    dat_strikes$cogb <- ifelse(dat_strikes$sex=="F", 1, 0)
  }else{
    dat_strikes$cogb <- ifelse(dat_strikes$race !=3, 1, 0)
  }
  
  num_cog <- sum(dat_strikes$cogb)
  num_t <- nrow(dat_strikes)
  subs <- data.frame(round = c(1:num_t), 
                     num_cog = NA, 
                     total = NA)
  subs$num_cog[1] <- num_cog
  subs$total[1] <- num_t
  for ( j in 2:num_t){
    num_cog = num_cog-dat_strikes$cogb[j-1]
    num_total = num_t - dat_strikes$strike_seq[j-1]
    subs$num_cog[j] <- num_cog
    # number of females struck in this and previous rounds
    subs$total[j] <- num_total
  }
  subs <- cbind(subs,dat_strikes$cogb)
  colnames(subs)[4] = 'cognizable'
  if(pp){
    df_m <- as.matrix(subs[which(dat_strikes$Disp=='PP'),])
  }else{
    df_m <- as.matrix(subs[which(dat_strikes$Disp=='PD'),])
  }
  return(df_m)
}
subset <- function(atny_name,pp,dat,cog){
  dat_sub <- extract_atny(atny_name,pp,dat)
  sub1 <- dat_sub %>% group_split(ID)
  sub1_l <- lapply(1:length(sub1), function(x) organize_input(sub1[[x]],pp,cog))
  df_m = do.call(rbind.data.frame,sub1_l)
  df_m <- as.matrix(df_m)
}
df_mp <- df %>%
                filter(party == "PP") %>%
                select(-c(party)) %>%
                as.matrix()

df_md <- df %>%
                filter(party == "PD") %>%
                select(-c(party)) %>%
                as.matrix()

sub_p <- subset("Brian P. Leaming",TRUE,dat0,"race")
sub_d <- subset("Frank J. Riccio II",FALSE,dat0,"race")
out_p <- make_posterior_p(x = df_mp,x_p =sub_p,a0 = 1, niter = 110000, 
                                          theta_start_val = 0, theta_proposal_sd =.5, 
                                          prior_mean = 0, prior_sd = 2)
pp_prior_theta <- make_posterior_prior(x_p=sub_p,a0 = 1, niter = 110000, 
                                        theta_start_val = 0, theta_proposal_sd =.5, 
                                                       prior_mean = 0, prior_sd = 2)
d_p <- data.frame(
                theta = out_p$theta[10001:110000],
                party = "Prosecution", 
                posterior = "Posterior")
pp_prior <- data.frame(theta = pp_prior_theta$theta[10001:110000], 
                                       party = "Prosecution", 
                                       posterior = "Prior")

out_d <- make_posterior_p(x = df_md,x_p = sub_d,a0= 1, niter = 110000, 
                                          theta_start_val = 0, theta_proposal_sd =.5, 
                                          prior_mean = 0, prior_sd = 2)
pd_prior_theta <- make_posterior_prior(x_p=sub_d,a0 = 1, niter = 110000, 
                                        theta_start_val = 0, theta_proposal_sd =.5, 
                                        prior_mean = 0, prior_sd = 2)
pd_prior <- data.frame(theta = pd_prior_theta$theta[10001:110000], 
                                       party = "Defense", 
                                       posterior = "Prior")
d_d <- data.frame(
                theta = out_d$theta[10001:110000],
                party = "Defense", 
                posterior = "Posterior")

dat <- rbind(d_p,d_d)
priors <- rbind(pp_prior, pd_prior)
dat <- rbind(dat, priors)
dat$party <- factor(dat$party, levels = c("Defense", "Prosecution"), 
                                ordered = TRUE)
CI <- dat %>% filter(posterior == 'Posterior') %>%
                group_by(party) %>%
                summarise(q1 = quantile(theta,0.1), q2 = quantile(theta,0.9)) %>%
                mutate(bias = ifelse(
                    q1 <= 0 & q2 >= 0, "No Bias", "Bias"))
pplot <- ggplot(data=dat) + 
                geom_density(aes(x = theta, 
                                 fill = interaction(party, posterior),
                                 color = interaction(party, posterior),
                                 alpha = interaction(party, posterior), 
                                 ..scaled..))+
                facet_wrap(~party, nrow =2)

pplot <- pplot  + theme_minimal() +
                 labs (title = "Likely values of b") +
                 xlab("") + 
                 ylab("") + 
                 xlim(c(-6,6)) +
                 scale_fill_manual("Group", values = c("blue", "darkred", "grey", "grey")) +
                 scale_color_manual("Group", values = c("blue", "darkred", "grey", "grey")) +
                 scale_alpha_manual("Group", values = c(0.3, 0.3, 0.1, 0.1)) +
                
                  # edit text sizes for plot
                 theme(legend.position="none",
                       axis.text = element_text(size = 16), 
                       strip.text = element_text(size = 18), 
                       plot.title = element_text(size = 24),
                       plot.subtitle = element_text(size = 16)) +
                  # add line at zero for reference
                 geom_vline(xintercept = 0, color = "black", lwd=1.5)

 pplot + geom_vline(data=CI, aes(xintercept=q1), color = c("blue", "darkred"),
                               linetype="dashed", size = 0.9)+
                    geom_vline(data=CI, aes(xintercept=q2), color = c("blue", "darkred"),
                           linetype="dashed", size = 0.9) 
 
```

The grey curve represents the probability density of the prior, the blue curve represents the posterior probability density of the defendant and the red curve represents the posterior probability density of the prosecutor. The two vertical dotted line represents the 80\% credible interval. 

We can find the majority part of both the prior and posterior density curve are on the right side of zero, and the 80\% credible interval is also on the right side of zero, indicating a bias of "Brian P. Leaming" and "Frank J. Riccio II" against the potential juror within the cognizable class of race. If we are interested in cognizable class of gender, we can modify our selection of cognizable class, and the density plot becomes figure \@ref(fig:brian2).

```{r brian2, echo=FALSE,fig.cap="Posterior Density Plot"}

load_path2 <- here::here("app/mh_sampler_pp.cpp")
load_path3 <- here::here("app/jury_data_cleaned_new.rds")

sourceCpp(load_path2)

dat0 <- readRDS(load_path3)

df <- data.frame(round = c(1:10),
                 num_cog = c(4,4,4,3,2,2,2,2,2,2),
                 total = c(15,14,13,12,11,10,9,8,7,6),
                 cog = c(0,1,1,0,0,1,1,0,0,0),
                 party = rep(c("PP","PD"),5))

extract_atny <- function(atny_name,pp,dat){
  if(pp){
    idx = sapply(1:nrow(dat),function(x) grepl(atny_name, dat$P_atty_l[x], fixed=TRUE))
    return(dat[which(idx),])
  }
  else{
    idx = sapply(1:nrow(dat),function(x) grepl(atny_name, dat$D_atty_l[x], fixed=TRUE))
    return(dat[which(idx),])
  }
} 
organize_input <- function(dat,pp,cog){
  dat_strikes <- dat %>% filter(!is.na(strike_seq)) 
  if(cog=='gender'){
    dat_strikes <- dat_strikes %>% filter(!is.na(sex))
  }else{
    dat_strikes <- dat_strikes %>% filter(!is.na(race))
  }
  
  dat_strikes <- dat_strikes[order(dat_strikes$strike_seq),]
  if(cog=='gender'){
    dat_strikes$cogb <- ifelse(dat_strikes$sex=="F", 1, 0)
  }else{
    dat_strikes$cogb <- ifelse(dat_strikes$race !=3, 1, 0)
  }
  
  num_cog <- sum(dat_strikes$cogb)
  num_t <- nrow(dat_strikes)
  subs <- data.frame(round = c(1:num_t), 
                     num_cog = NA, 
                     total = NA)
  subs$num_cog[1] <- num_cog
  subs$total[1] <- num_t
  for ( j in 2:num_t){
    num_cog = num_cog-dat_strikes$cogb[j-1]
    num_total = num_t - dat_strikes$strike_seq[j-1]
    subs$num_cog[j] <- num_cog
    # number of females struck in this and previous rounds
    subs$total[j] <- num_total
  }
  subs <- cbind(subs,dat_strikes$cogb)
  colnames(subs)[4] = 'cognizable'
  if(pp){
    df_m <- as.matrix(subs[which(dat_strikes$Disp=='PP'),])
  }else{
    df_m <- as.matrix(subs[which(dat_strikes$Disp=='PD'),])
  }
  return(df_m)
}
subset <- function(atny_name,pp,dat,cog){
  dat_sub <- extract_atny(atny_name,pp,dat)
  sub1 <- dat_sub %>% group_split(ID)
  sub1_l <- lapply(1:length(sub1), function(x) organize_input(sub1[[x]],pp,cog))
  df_m = do.call(rbind.data.frame,sub1_l)
  df_m <- as.matrix(df_m)
}
df_mp <- df %>%
                filter(party == "PP") %>%
                select(-c(party)) %>%
                as.matrix()

df_md <- df %>%
                filter(party == "PD") %>%
                select(-c(party)) %>%
                as.matrix()

sub_p <- subset("Brian P. Leaming",TRUE,dat0,"gender")
sub_d <- subset("Frank J. Riccio II",FALSE,dat0,"gender")
out_p <- make_posterior_p(x = df_mp,x_p =sub_p,a0 = 1, niter = 110000, 
                                          theta_start_val = 0, theta_proposal_sd =.5, 
                                          prior_mean = 0, prior_sd = 2)
pp_prior_theta <- make_posterior_prior(x_p=sub_p,a0 = 1, niter = 110000, 
                                        theta_start_val = 0, theta_proposal_sd =.5, 
                                                       prior_mean = 0, prior_sd = 2)
d_p <- data.frame(
                theta = out_p$theta[10001:110000],
                party = "Prosecution", 
                posterior = "Posterior")
pp_prior <- data.frame(theta = pp_prior_theta$theta[10001:110000], 
                                       party = "Prosecution", 
                                       posterior = "Prior")

out_d <- make_posterior_p(x = df_md,x_p = sub_d,a0= 1, niter = 110000, 
                                          theta_start_val = 0, theta_proposal_sd =.5, 
                                          prior_mean = 0, prior_sd = 2)
pd_prior_theta <- make_posterior_prior(x_p=sub_d,a0 = 1, niter = 110000, 
                                        theta_start_val = 0, theta_proposal_sd =.5, 
                                        prior_mean = 0, prior_sd = 2)
pd_prior <- data.frame(theta = pd_prior_theta$theta[10001:110000], 
                                       party = "Defense", 
                                       posterior = "Prior")
d_d <- data.frame(
                theta = out_d$theta[10001:110000],
                party = "Defense", 
                posterior = "Posterior")

dat <- rbind(d_p,d_d)
priors <- rbind(pp_prior, pd_prior)
dat <- rbind(dat, priors)
dat$party <- factor(dat$party, levels = c("Defense", "Prosecution"), 
                                ordered = TRUE)
CI <- dat %>% filter(posterior == 'Posterior') %>%
                group_by(party) %>%
                summarise(q1 = quantile(theta,0.1), q2 = quantile(theta,0.9)) %>%
                mutate(bias = ifelse(
                    q1 <= 0 & q2 >= 0, "No Bias", "Bias"))
pplot <- ggplot(data=dat) + 
                geom_density(aes(x = theta, 
                                 fill = interaction(party, posterior),
                                 color = interaction(party, posterior),
                                 alpha = interaction(party, posterior), 
                                 ..scaled..))+
                facet_wrap(~party, nrow =2)

pplot <- pplot  + theme_minimal() +
                 labs (title = "Likely values of b") +
                 xlab("") + 
                 ylab("") + 
                 xlim(c(-6,6)) +
                 scale_fill_manual("Group", values = c("blue", "darkred", "grey", "grey")) +
                 scale_color_manual("Group", values = c("blue", "darkred", "grey", "grey")) +
                 scale_alpha_manual("Group", values = c(0.3, 0.3, 0.1, 0.1)) +
                
                  # edit text sizes for plot
                 theme(legend.position="none",
                       axis.text = element_text(size = 16), 
                       strip.text = element_text(size = 18), 
                       plot.title = element_text(size = 24),
                       plot.subtitle = element_text(size = 16)) +
                  # add line at zero for reference
                 geom_vline(xintercept = 0, color = "black", lwd=1.5)

 pplot + geom_vline(data=CI, aes(xintercept=q1), color = c("blue", "darkred"),
                               linetype="dashed", size = 0.9)+
                    geom_vline(data=CI, aes(xintercept=q2), color = c("blue", "darkred"),
                           linetype="dashed", size = 0.9) 
```

When we consider cognizable class gender, we can find most of the density curve of both prior and posterior are on the left of zero, indicating the possible preference for the potential jurors within the cognizable class. However, the 80\% credible interval includes 0, thus the preference for the cognizable class of "Brian P. Leaming" and "Frank J. Riccio II" is not statistically significant. If we give low weight on historical information, the density plot will be as shown in figure \@ref(fig:brian3).

```{r brian3, echo=FALSE,fig.cap="Posterior Density Plot"}
load_path2 <- here::here("app/mh_sampler_pp.cpp")
load_path3 <- here::here("app/jury_data_cleaned_new.rds")
sourceCpp(load_path2)
sourceCpp(load_path2)
dat0 <- readRDS(load_path3)
df <- data.frame(round = c(1:10),
                 num_cog = c(4,4,4,3,2,2,2,2,2,2),
                 total = c(15,14,13,12,11,10,9,8,7,6),
                 cog = c(0,1,1,0,0,1,1,0,0,0),
                 party = rep(c("PP","PD"),5))
extract_atny <- function(atny_name,pp,dat){
  if(pp){
    idx = sapply(1:nrow(dat),function(x) grepl(atny_name, dat$P_atty_l[x], fixed=TRUE))
    return(dat[which(idx),])
  }
  else{
    idx = sapply(1:nrow(dat),function(x) grepl(atny_name, dat$D_atty_l[x], fixed=TRUE))
    return(dat[which(idx),])
  }
} 
organize_input <- function(dat,pp,cog){
  dat_strikes <- dat %>% filter(!is.na(strike_seq)) 
  if(cog=='gender'){
    dat_strikes <- dat_strikes %>% filter(!is.na(sex))
  }else{
    dat_strikes <- dat_strikes %>% filter(!is.na(race))
  }
  
  dat_strikes <- dat_strikes[order(dat_strikes$strike_seq),]
  if(cog=='gender'){
    dat_strikes$cogb <- ifelse(dat_strikes$sex=="F", 1, 0)
  }else{
    dat_strikes$cogb <- ifelse(dat_strikes$race !=3, 1, 0)
  }
  
  num_cog <- sum(dat_strikes$cogb)
  num_t <- nrow(dat_strikes)
  subs <- data.frame(round = c(1:num_t), 
                     num_cog = NA, 
                     total = NA)
  subs$num_cog[1] <- num_cog
  subs$total[1] <- num_t
  for ( j in 2:num_t){
    num_cog = num_cog-dat_strikes$cogb[j-1]
    num_total = num_t - dat_strikes$strike_seq[j-1]
    subs$num_cog[j] <- num_cog
    # number of females struck in this and previous rounds
    subs$total[j] <- num_total
  }
  subs <- cbind(subs,dat_strikes$cogb)
  colnames(subs)[4] = 'cognizable'
  if(pp){
    df_m <- as.matrix(subs[which(dat_strikes$Disp=='PP'),])
  }else{
    df_m <- as.matrix(subs[which(dat_strikes$Disp=='PD'),])
  }
  return(df_m)
}
subset <- function(atny_name,pp,dat,cog){
  dat_sub <- extract_atny(atny_name,pp,dat)
  sub1 <- dat_sub %>% group_split(ID)
  sub1_l <- lapply(1:length(sub1), function(x) organize_input(sub1[[x]],pp,cog))
  df_m = do.call(rbind.data.frame,sub1_l)
  df_m <- as.matrix(df_m)
}
df_mp <- df %>%
                filter(party == "PP") %>%
                select(-c(party)) %>%
                as.matrix()

df_md <- df %>%
                filter(party == "PD") %>%
                select(-c(party)) %>%
                as.matrix()

sub_p <- subset("Brian P. Leaming",TRUE,dat0,"gender")
sub_d <- subset("Frank J. Riccio II",FALSE,dat0,"gender")
out_p <- make_posterior_p(x = df_mp,x_p =sub_p,a0 = 0.2, niter = 110000, 
                                          theta_start_val = 0, theta_proposal_sd =.5, 
                                          prior_mean = 0, prior_sd = 2)
pp_prior_theta <- make_posterior_prior(x_p=sub_p,a0 = 0.2, niter = 110000, 
                                        theta_start_val = 0, theta_proposal_sd =.5, 
                                                       prior_mean = 0, prior_sd = 2)
d_p <- data.frame(
                theta = out_p$theta[10001:110000],
                party = "Prosecution", 
                posterior = "Posterior")
pp_prior <- data.frame(theta = pp_prior_theta$theta[10001:110000], 
                                       party = "Prosecution", 
                                       posterior = "Prior")

out_d <- make_posterior_p(x = df_md,x_p = sub_d,a0= 0.2, niter = 110000, 
                                          theta_start_val = 0, theta_proposal_sd =.5, 
                                          prior_mean = 0, prior_sd = 2)
pd_prior_theta <- make_posterior_prior(x_p=sub_d,a0 = 0.2, niter = 110000, 
                                        theta_start_val = 0, theta_proposal_sd =.5, 
                                        prior_mean = 0, prior_sd = 2)
pd_prior <- data.frame(theta = pd_prior_theta$theta[10001:110000], 
                                       party = "Defense", 
                                       posterior = "Prior")
d_d <- data.frame(
                theta = out_d$theta[10001:110000],
                party = "Defense", 
                posterior = "Posterior")

dat <- rbind(d_p,d_d)
priors <- rbind(pp_prior, pd_prior)
dat <- rbind(dat, priors)
dat$party <- factor(dat$party, levels = c("Defense", "Prosecution"), 
                                ordered = TRUE)
CI <- dat %>% filter(posterior == 'Posterior') %>%
                group_by(party) %>%
                summarise(q1 = quantile(theta,0.1), q2 = quantile(theta,0.9)) %>%
                mutate(bias = ifelse(
                    q1 <= 0 & q2 >= 0, "No Bias", "Bias"))
pplot <- ggplot(data=dat) + 
                geom_density(aes(x = theta, 
                                 fill = interaction(party, posterior),
                                 color = interaction(party, posterior),
                                 alpha = interaction(party, posterior), 
                                 ..scaled..))+
                facet_wrap(~party, nrow =2)

pplot <- pplot  + theme_minimal() +
                 labs (title = "Likely values of b") +
                 xlab("") + 
                 ylab("") + 
                 xlim(c(-6,6)) +
                 scale_fill_manual("Group", values = c("blue", "darkred", "grey", "grey")) +
                 scale_color_manual("Group", values = c("blue", "darkred", "grey", "grey")) +
                 scale_alpha_manual("Group", values = c(0.3, 0.3, 0.1, 0.1)) +
                
                  # edit text sizes for plot
                 theme(legend.position="none",
                       axis.text = element_text(size = 16), 
                       strip.text = element_text(size = 18), 
                       plot.title = element_text(size = 24),
                       plot.subtitle = element_text(size = 16)) +
                  # add line at zero for reference
                 geom_vline(xintercept = 0, color = "black", lwd=1.5)

 pplot + geom_vline(data=CI, aes(xintercept=q1), color = c("blue", "darkred"),
                               linetype="dashed", size = 0.9)+
                    geom_vline(data=CI, aes(xintercept=q2), color = c("blue", "darkred"),
                           linetype="dashed", size = 0.9) 
```

We can find both the prior and posterior density become more flat, and the posterior density looks like symmetric around zero now.


# Conclusion


# CRediT Author Statement

Sachin S. Pandya: Conceptualization, Investigation, Software, Writing; Xiaomeng Li: Conceptualization, Formal Analysis, Software, Writing - original draft; Timothy Moore: Conceptualization, Supervision, Visualization. Based on categories in https://casrai.org/credit/].

# References
